#!/bin/bash

#=================================================
# GENERIC START
#=================================================
# IMPORT GENERIC HELPERS
#=================================================

# Keep this path for calling _common.sh inside the execution's context of backup and restore scripts
source ../settings/scripts/_common.sh
source /usr/share/yunohost/helpers

#=================================================
# MANAGE SCRIPT FAILURE
#=================================================

ynh_clean_setup () {
	true
}
# Exit if an error occurs during the execution of the script
ynh_abort_if_errors

#=================================================
# LOAD SETTINGS
#=================================================
ynh_script_progression --message="Loading settings..." --weight=1

app=$YNH_APP_INSTANCE_NAME

domain=$(ynh_app_setting_get --app=$app --key=domain)
path_url=$(ynh_app_setting_get --app=$app --key=path)
final_path=$(ynh_app_setting_get --app=$app --key=final_path)
datadir=$(ynh_app_setting_get --app=$app --key=datadir)
yunorunner_instance=$(ynh_app_setting_get --app=$app --key=yunorunner_instance)
cluster=$(ynh_app_setting_get --app=$app --key=cluster)
ci_type=$(ynh_app_setting_get --app=$app --key=ci_type)

#=================================================
# CHECK IF THE APP CAN BE RESTORED
#=================================================
ynh_script_progression --message="Validating restoration parameters..." --weight=1

test ! -d $final_path \
	|| ynh_die --message="There is already a directory: $final_path "

use_new_yunorunner_instance=0
if ! yunohost app list --output-as json --quiet | jq -e --arg id $yunorunner_instance '.apps[] | select(.id == $id)' >/dev/null
then
	use_new_yunorunner_instance=1
fi
use_new_lxd_instance=0
if ! yunohost app list --output-as json --quiet | jq -e --arg id lxd '.apps[] | select(.id == $id)' >/dev/null
then
	use_new_lxd_instance=1
fi

#=================================================
# STANDARD RESTORATION STEPS
#=================================================
# REINSTALL DEPENDENCIES
#=================================================
ynh_script_progression --message="Reinstalling dependencies..." --weight=1

# Define and install dependencies
ynh_exec_warn_less ynh_install_app_dependencies $pkg_dependencies
if [ $use_new_yunorunner_instance -eq 1 ]; then
	#app_dependencies="$app_dependencies yunorunner?domain=$domain&path=$path_url&ci_package_check_path=$final_path&ci_package_check_datadir=$datadir"
	yunohost app install https://github.com/YunoHost-Apps/yunorunner_ynh/tree/596041cca073731a3fec7ea14fa1687ca27f4f56 --force --args "domain=$domain&path=$path_url&ci_package_check_path=$final_path&ci_package_check_datadir=$datadir"
fi
ynh_install_apps --apps="$app_dependencies"
if [ $use_new_yunorunner_instance -eq 1 ]; then
	yunorunner_instance=$(yunohost app list --output-as json --quiet | jq -re '.apps[] | select(.id  | contains("yunorunner")) | .id' | sort -V | tail -1)
	ynh_app_setting_set --app=$app --key=yunorunner_instance --value=$yunorunner_instance
fi

#=================================================
# RESTORE THE APP MAIN DIR
#=================================================
ynh_script_progression --message="Restoring the app main directory..." --weight=1

ynh_restore_file --origin_path="$final_path"

chmod 750 "$final_path"
chmod -R o-rwx "$final_path"
chown -R $yunorunner_instance:www-data "$final_path"

#=================================================
# RESTORE THE DATA DIRECTORY
#=================================================
ynh_script_progression --message="Restoring the data directory..." --weight=1

ynh_restore_file --origin_path="$datadir" --not_mandatory

mkdir -p $datadir/logs
ln -fs $datadir/badges $final_path/badges
ln -fs $datadir/logs $final_path/logs
ln -fs $datadir/summary $final_path/summary

chmod 750 "$datadir"
chmod -R o-rwx "$datadir"
chown -R $yunorunner_instance:www-data "$datadir"

#=================================================
# SPECIFIC RESTORATION
#=================================================
# RESTORE VARIOUS FILES
#=================================================
ynh_script_progression --message="Restoring various files..." --weight=1

ynh_restore_file --origin_path="/etc/cron.d/$app"

#=================================================
# CONFIGURE YUNORUNNER
#=================================================

if [[ $yunorunner_instance == *"yunorunner"* ]]
then
	ynh_script_progression --message="Configuring YunoRunner..." --weight=1
	# Retrieve YunoRunner settings
	yunorunner_port=$(ynh_app_setting_get --app=$yunorunner_instance --key=port)
	yunorunner_final_path=$(ynh_app_setting_get --app=$yunorunner_instance --key=final_path)

	# Stop YunoRunner
	ynh_systemd_action --service_name=$yunorunner_instance --action="stop" --log_path="systemd" --line_match="Stopped YunoRunner CI"

	if [ $use_new_yunorunner_instance -eq 1 ]; then
		# Remove the original database, in order to rebuilt it with the new config.
		ynh_secure_remove --file="$yunorunner_final_path/db.sqlite"

		# Create a random token for ciclic
		cat /dev/urandom | tr -dc _A-Za-z0-9 | head -c80 | tee $yunorunner_final_path/token $yunorunner_final_path/tokens
	fi

	# For automatic / "main" CI we want to auto schedule jobs using the app list
	if [ $ci_type == "auto" ]
	then
		monitor_apps_list="True"
		monitor_git="True"
		monitor_only_good_quality_apps="False"
		monthly_jobs="True"
		worker_count="1"
	# For Dev CI, we want to control the job scheduling entirely
	# (c.f. the github webhooks or scan_for_new_jobs_from_chroots cron job)
	else
		monitor_apps_list="False"
		monitor_git="False"
		monitor_only_good_quality_apps="False"
		monthly_jobs="False"
		worker_count="1"
	fi
	ynh_app_setting_set --app=$app --key=monitor_apps_list --value=$monitor_apps_list
	ynh_app_setting_set --app=$app --key=monitor_git --value=$monitor_git
	ynh_app_setting_set --app=$app --key=monitor_only_good_quality_apps --value=$monitor_only_good_quality_apps
	ynh_app_setting_set --app=$app --key=monthly_jobs --value=$monthly_jobs
	ynh_app_setting_set --app=$app --key=worker_count --value=$worker_count

	ynh_add_config --template="yunorunner.config.py" --destination="$yunorunner_final_path/config.py"

	chmod 400 "$yunorunner_final_path/config.py"
	chown $yunorunner_instance:$yunorunner_instance "$yunorunner_final_path/config.py"

	yunohost app makedefault -d "$domain" $yunorunner_instance
fi

#=================================================
# CONFIGURE LXD
#=================================================
ynh_script_progression --message="Configuring LXD..." --weight=1

if [ $use_new_lxd_instance -eq 1 ]
then
	if [ $cluster -eq 1 ]
	then
		local free_space=$(df --output=avail / | sed 1d)
		local btrfs_size=$(( $free_space * 90 / 100 / 1024 / 1024 ))
		local lxc_network=$((1 + $RANDOM % 254))

		yunohost firewall allow TCP 8443
		ynh_add_config --template="preseed.conf" --destination="$final_path/preseed.conf"
		cat "$final_path/preseed.conf" | lxd init --preseed
		ynh_delete_file_checksum --file="$final_path/preseed.conf"
		ynh_secure_remove --file="$final_path/preseed.conf"
		lxc config set core.https_address [::]
	else
		lxd init --auto --storage-backend=dir
	fi
fi

# ci_user will be the one launching job, gives it permission to run lxd commands
usermod -a -G lxd $yunorunner_instance

# We need a home for the "su" command later ?
mkdir -p /home/$yunorunner_instance
chown -R $yunorunner_instance /home/$yunorunner_instance

su $yunorunner_instance -s /bin/bash -c "lxc remote add yunohost https://devbaseimgs.yunohost.org --public --accept-certificate"

lxdbr0_network_address=$(lxc network get lxdbr0  ipv4.address | cut -d'.' -f1-3)
mkdir -p "/etc/yunohost/hooks.d/post_iptable_rules/"
ynh_add_config --template="95-lxd-custom" --destination="/etc/yunohost/hooks.d/post_iptable_rules/95-lxd-custom"
chmod +x /etc/yunohost/hooks.d/post_iptable_rules/95-lxd-custom
/etc/yunohost/hooks.d/post_iptable_rules/95-lxd-custom

#=================================================
# INTEGRATE SERVICE IN YUNOHOST
#=================================================
ynh_script_progression --message="Integrating service in YunoHost..." --weight=1

if [ $cluster -eq 1 ]
then
	yunohost service add lxd --log="/var/log/lxd/lxd.log" --needs_exposed_ports 8443
fi

#=================================================
# START SYSTEMD SERVICE
#=================================================

if [[ $yunorunner_instance == *"yunorunner"* ]]
then
	ynh_script_progression --message="Starting a systemd service..." --weight=1

	# Start a systemd service
	ynh_systemd_action --service_name=$yunorunner_instance --action="start" --log_path="systemd" --line_match="Started YunoRunner CI" --timeout=30
fi

#=================================================
# GENERIC FINALIZATION
#=================================================
# END OF SCRIPT
#=================================================

ynh_script_progression --message="Restoration completed for $app" --last
